{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Loader Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nfs/inf6/data/datasets/MOVi/movi_c/validation rgb*.png\n",
      "rgb*.png 6000\n",
      "/home/nfs/inf6/data/datasets/MOVi/movi_c/validation mask*.png\n",
      "mask*.png 0\n",
      "/home/nfs/inf6/data/datasets/MOVi/movi_c/validation flow*.png\n",
      "flow*.png 6000\n",
      "/home/nfs/inf6/data/datasets/MOVi/movi_c/validation coords*.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"/home/nfs/inf6/data/datasets/MOVi/movi_c/validation\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m/home/nfs/inf6/data/datasets/MOVi/movi_c/train\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m path=\u001b[33m'\u001b[39m\u001b[33m/home/nfs/inf6/data/datasets/MOVi/movi_c/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vl=\u001b[43mVideoLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalidation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(vl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VideoTracker/loader/videoLoader.py:31\u001b[39m, in \u001b[36mVideoLoader.__init__\u001b[39m\u001b[34m(self, data_path, split, transforms)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mself\u001b[39m.mask=\u001b[38;5;28mself\u001b[39m.read_files(data_directory,\u001b[33m'\u001b[39m\u001b[33mmask*.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mself\u001b[39m.flow=\u001b[38;5;28mself\u001b[39m.read_files(data_directory,\u001b[33m'\u001b[39m\u001b[33mflow*.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28mself\u001b[39m.coord=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcoords*.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m.rgb)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m.mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VideoTracker/loader/videoLoader.py:17\u001b[39m, in \u001b[36mVideoLoader.read_files\u001b[39m\u001b[34m(self, data_directory, condition)\u001b[39m\n\u001b[32m     15\u001b[39m     retrieved_files = [io.read_image(path=file).to(torch.float32) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m retrieved_addresses]\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m condition.endswith(\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     retrieved_files = [\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m.to(torch.float32) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m retrieved_addresses]\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(condition,\u001b[38;5;28mlen\u001b[39m(retrieved_files))\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retrieved_files\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VideoTracker/venv/lib/python3.12/site-packages/torchvision/io/image.py:337\u001b[39m, in \u001b[36mread_image\u001b[39m\u001b[34m(path, mode, apply_exif_orientation)\u001b[39m\n\u001b[32m    335\u001b[39m     _log_api_usage_once(read_image)\n\u001b[32m    336\u001b[39m data = read_file(path)\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_exif_orientation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapply_exif_orientation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VideoTracker/venv/lib/python3.12/site-packages/torchvision/io/image.py:324\u001b[39m, in \u001b[36mdecode_image\u001b[39m\u001b[34m(input, mode, apply_exif_orientation)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    323\u001b[39m     mode = ImageReadMode[mode.upper()]\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_exif_orientation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VideoTracker/venv/lib/python3.12/site-packages/torch/_ops.py:1243\u001b[39m, in \u001b[36mOpOverloadPacket.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly."
     ]
    }
   ],
   "source": [
    "from loader.videoLoader import VideoLoader\n",
    "\"\"\"/home/nfs/inf6/data/datasets/MOVi/movi_c/validation\n",
    "/home/nfs/inf6/data/datasets/MOVi/movi_c/train\"\"\"\n",
    "path='/home/nfs/inf6/data/datasets/MOVi/movi_c/'\n",
    "vl=VideoLoader(path,split='validation')\n",
    "print(vl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch Environment (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
